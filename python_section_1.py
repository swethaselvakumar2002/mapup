# -*- coding: utf-8 -*-
"""python_section_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19RQS7GFH9vwsJJdITqVQzJAeC1M4FeWx

**Question 1: Reverse List by N Elements**
"""

def reverse(lst, n):
    result = []
    length = len(lst)

    for i in range(0, length, n):
        temp = []

        for j in range(i, min(i + n, length)):
            temp.append(lst[j])

        for j in range(len(temp) - 1, -1, -1):
            result.append(temp[j])

    return result

# Example
print(reverse([1, 2, 3, 4, 5, 6, 7, 8], 3))
print(reverse([1, 2, 3, 4, 5], 2))
print(reverse([10, 20, 30, 40, 50, 60, 70], 4))

"""**Question 2: Lists & Dictionaries**"""

def group_length(strings):

    length_dict = {}

    for string in strings:
        length = len(string)
        if length not in length_dict:
            length_dict[length] = []

        length_dict[length].append(string)

    sorted_dict = dict(sorted(length_dict.items()))

    return sorted_dict


print(group_length(["apple", "bat", "car", "elephant", "dog", "bear"]))
print(group_length(["one", "two", "three", "four"]))

"""**Question 3: Flatten a Nested Dictionary**"""

def flat_dict(nested_dict):
    flattened = {}
    stack = [(nested_dict, '')]

    while stack:
        current_dict, parent_key = stack.pop()

        for key, value in current_dict.items():
            new_key = f"{parent_key}.{key}" if parent_key else key

            if isinstance(value, dict):
                stack.append((value, new_key))
            elif isinstance(value, list):
                for i, item in enumerate(value):
                    if isinstance(item, dict):
                        stack.append((item, f"{new_key}[{i}]"))
                    else:
                        flattened[f"{new_key}[{i}]"] = item
            else:
                flattened[new_key] = value

    return flattened


nested_dict = {
    "road": {
        "name": "Highway 1",
        "length": 350,
        "sections": [
            {
                "id": 1,
                "condition": {
                    "pavement": "good",
                    "traffic": "moderate"
                }
            }
        ]
    }
}

flattened = flat_dict(nested_dict)
print(flattened)

"""**Question 4: Generate Unique Permutations**"""

def permute_unique(nums):
    def backtrack(start):
        if start == len(nums):
            print(nums[:])
            return

        seen = set()
        for i in range(start, len(nums)):
            if nums[i] in seen:
                continue

            seen.add(nums[i])
            nums[start], nums[i] = nums[i], nums[start]
            backtrack(start + 1)
            nums[start], nums[i] = nums[i], nums[start]

    nums.sort()
    backtrack(0)

input_list = [1, 1, 2]
permute_unique(input_list)

"""**Question 5: Find All Dates in a Text**"""

import re

def find_all_dates(text):
    patterns = [
        r'\b(\d{2})-(\d{2})-(\d{4})\b',
        r'\b(\d{2})/(\d{2})/(\d{4})\b',
        r'\b(\d{4})\.(\d{2})\.(\d{2})\b'
    ]

    combined_pattern = '|'.join(patterns)
    matches = re.findall(combined_pattern, text)

    valid_dates = []
    for match in matches:
        if match[0]:
            valid_dates.append(f"{match[0]}-{match[1]}-{match[2]}")
        elif match[3]:
            valid_dates.append(f"{match[3]}/{match[4]}/{match[5]}")
        elif match[6]:
            valid_dates.append(f"{match[6]}.{match[7]}.{match[8]}")

    return valid_dates

text = "I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23."
output = find_all_dates(text)
print(output)

"""**Question 6: Decode Polyline, Convert to DataFrame with Distances**"""

!pip install polyline

import polyline
import pandas as pd
import numpy as np

def haversine(lat1, lon1, lat2, lon2):
    R = 6371000  # Radius of Earth in meters
    phi1 = np.radians(lat1)
    phi2 = np.radians(lat2)
    delta_phi = np.radians(lat2 - lat1)
    delta_lambda = np.radians(lon2 - lon1)

    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))

    return R * c  # Distance in meters

def decode_polyline_to_dataframe(polyline_str):
    decoded_coords = polyline.decode(polyline_str)

    data = {
        'latitude': [],
        'longitude': [],
        'distance': []
    }

    total_distance = 0
    for i in range(len(decoded_coords)):
        lat, lon = decoded_coords[i]
        data['latitude'].append(lat)
        data['longitude'].append(lon)

        if i > 0:
            distance = haversine(decoded_coords[i-1][0], decoded_coords[i-1][1], lat, lon)
            total_distance += distance
            data['distance'].append(distance)
        else:
            data['distance'].append(0)  # First point has no previous point

    df = pd.DataFrame(data)
    return df

# Example usage
polyline_str = "u{~vH}l|b@_@`@a@f@c@h@i@h@k@_@f@a@d@q@d@o@b@e@"
df = decode_polyline_to_dataframe(polyline_str)
print(df)

"""**Question 7: Matrix Rotation and Transformation**"""

def rotate_and_transform_matrix(matrix):
    n = len(matrix)

    for i in range(n):
        for j in range(i + 1, n):
            matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]

    for i in range(n):
        matrix[i].reverse()

    final_matrix = [[0] * n for _ in range(n)]

    for i in range(n):
        for j in range(n):
            row_sum = sum(matrix[i])
            col_sum = sum(matrix[k][j] for k in range(n))
            final_matrix[i][j] = row_sum + col_sum - matrix[i][j]

    return final_matrix

matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
result = rotate_and_transform_matrix(matrix)
for row in result:
    print(row)

"""**Question 8: Time Check**"""

import pandas as pd
df=pd.read_csv("/content/dataset-1.csv")
print(df.head())

import pandas as pd

def check_time_data_completeness(df):

    df['start_datetime'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'], format='%A %H:%M:%S', errors='coerce')
    df['end_datetime'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'], format='%A %H:%M:%S', errors='coerce')

    df.set_index(['id', 'id_2'], inplace=True)
    grouped = df.groupby(level=['id', 'id_2'])
    results = {}
    for (id_val, id_2_val), group in grouped:
        days_covered = set()
        full_day_coverage = True

        for _, row in group.iterrows():
            if pd.isnull(row['start_datetime']) or pd.isnull(row['end_datetime']):
                full_day_coverage = False
                continue

            start_day = row['start_datetime'].date()
            end_day = row['end_datetime'].date()
            days_covered.add(start_day)
            days_covered.add(end_day)

            if not (row['start_datetime'].time() <= pd.Timestamp('00:00:00').time() and
                    row['end_datetime'].time() >= pd.Timestamp('23:59:59').time()):
                full_day_coverage = False

        all_days = {0, 1, 2, 3, 4, 5, 6}  # Monday to Sunday
        covered_days_indices = {day.weekday() for day in days_covered}

        results[(id_val, id_2_val)] = not (covered_days_indices == all_days and full_day_coverage)

    return pd.Series(results)

result_series = check_time_data_completeness(df)

# Display result
print(result_series)